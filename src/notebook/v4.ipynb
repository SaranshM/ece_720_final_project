{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55692 entries, 0 to 55691\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   gender               55692 non-null  object \n",
      " 1   age                  55692 non-null  int64  \n",
      " 2   height               55692 non-null  int64  \n",
      " 3   weight               55692 non-null  int64  \n",
      " 4   waist                55692 non-null  float64\n",
      " 5   eyesight_left        55692 non-null  float64\n",
      " 6   eyesight_right       55692 non-null  float64\n",
      " 7   hearing_left         55692 non-null  float64\n",
      " 8   hearing_right        55692 non-null  float64\n",
      " 9   systolic             55692 non-null  float64\n",
      " 10  relaxation           55692 non-null  float64\n",
      " 11  fasting_blood_sugar  55692 non-null  float64\n",
      " 12  cholesterol          55692 non-null  float64\n",
      " 13  triglyceride         55692 non-null  float64\n",
      " 14  hdl                  55692 non-null  float64\n",
      " 15  ldl                  55692 non-null  float64\n",
      " 16  hemoglobin           55692 non-null  float64\n",
      " 17  urine_protein        55692 non-null  float64\n",
      " 18  serum_creatinine     55692 non-null  float64\n",
      " 19  ast                  55692 non-null  float64\n",
      " 20  alt                  55692 non-null  float64\n",
      " 21  gtp                  55692 non-null  float64\n",
      " 22  oral                 55692 non-null  object \n",
      " 23  dental_caries        55692 non-null  int64  \n",
      " 24  tartar               55692 non-null  object \n",
      "dtypes: float64(18), int64(4), object(3)\n",
      "memory usage: 10.6+ MB\n",
      "(44360, 25)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "df = pd.read_csv(\"./data/smoking.csv\")\n",
    "\n",
    "# Renaming the columns for easier accessibility\n",
    "\n",
    "new_column_names = {\n",
    "    \"ID\": \"id\",\n",
    "    \"age\": \"age\",\n",
    "    \"height(cm)\": \"height\",\n",
    "    \"weight(kg)\": \"weight\",\n",
    "    \"waist(cm)\": \"waist\",\n",
    "    \"eyesight(left)\": \"eyesight_left\",\n",
    "    \"eyesight(right)\": \"eyesight_right\",\n",
    "    \"hearing(left)\": \"hearing_left\",\n",
    "    \"hearing(right)\": \"hearing_right\",\n",
    "    \"systolic\": \"systolic\",\n",
    "    \"relaxation\": \"relaxation\",\n",
    "    \"fasting blood sugar\": \"fasting_blood_sugar\",\n",
    "    \"Cholesterol\": \"cholesterol\",\n",
    "    \"triglyceride\": \"triglyceride\",\n",
    "    \"HDL\": \"hdl\",\n",
    "    \"LDL\": \"ldl\",\n",
    "    \"hemoglobin\": \"hemoglobin\",\n",
    "    \"Urine protein\": \"urine_protein\",\n",
    "    \"serum creatinine\": \"serum_creatinine\",\n",
    "    \"AST\": \"ast\",\n",
    "    \"ALT\": \"alt\",\n",
    "    \"Gtp\": \"gtp\",\n",
    "    \"dental caries\": \"dental_caries\",\n",
    "    \"smoking\": \"smoker_status\"\n",
    "}\n",
    "\n",
    "df.rename(columns = new_column_names, inplace = True)\n",
    "\n",
    "y_train = df[['id', 'smoker_status']].copy()\n",
    "\n",
    "x_train = df.drop(['id', 'smoker_status'], axis=1)\n",
    "\n",
    "x_train.info()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to calculate the IQR outlier cutoff\n",
    "def calculate_iqr_outliers(data, feature):\n",
    "    Q1 = data[feature].quantile(0.25)\n",
    "    Q3 = data[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Apply the function to each feature in the dataset\n",
    "outliers_indices = []\n",
    "\n",
    "for feature in x_train.columns:\n",
    "    if x_train[feature].dtype in ['float64', 'int64']:  # Only apply to numeric columns\n",
    "        lower_bound, upper_bound = calculate_iqr_outliers(x_train, feature)\n",
    "        feature_outliers = x_train[(x_train[feature] < lower_bound) | (x_train[feature] > upper_bound)].index\n",
    "        outliers_indices.extend(feature_outliers)\n",
    "\n",
    "# Determine which rows have outliers in multiple columns\n",
    "from collections import Counter\n",
    "outlier_counts = Counter(outliers_indices)\n",
    "multiple_outliers = [k for k, v in outlier_counts.items() if v > 1]\n",
    "\n",
    "x_train = x_train.drop(multiple_outliers)\n",
    "y_train = y_train.drop(multiple_outliers)\n",
    "\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Using cached h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from tensorflow) (4.10.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Using cached namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Using cached optree-0.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (45 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/saran/Desktop/ece_720_final_project/venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl (227.0 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "Using cached h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_12_0_arm64.whl (3.4 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.11.0-cp311-cp311-macosx_11_0_arm64.whl (274 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# One-hot encode categorical variables\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(x_train)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_train = pd.get_dummies(x_train)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features] for CNN\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
